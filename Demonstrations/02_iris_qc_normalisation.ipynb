{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ff9c1fd-a5b2-4836-a7c6-13d78b7da095",
   "metadata": {},
   "source": [
    "# Counts Matrix QC and Normalisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38516cc-4f71-4ea2-bd58-c5ea2169f2ad",
   "metadata": {},
   "source": [
    "## Table of contents  \n",
    "0. [Background](#background)\n",
    "1. [Ambient RNA correction](#rna_correction)\n",
    "2. [Reading data](#reading_data)\n",
    "3. [Gene annotation](#gene_annotation)\n",
    "4. [Filtering](#filtering)\n",
    "5. [Normalisation](#normalisation)\n",
    "6. [Pre-processing workflow](#workflow)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfa3662-5b06-4bb4-ae5f-9fa42348d77b",
   "metadata": {},
   "source": [
    "## 0. Background"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872da00d-6972-44bc-baa9-6c5aff81e8bc",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5f432c-f999-476d-b628-6ee4a3e64977",
   "metadata": {},
   "source": [
    "We are working with data from [Caron et al. 2020](https://doi.org/10.1038/s41598-020-64929-x), investigating the transcriptional profile of different types of childhood acute lymphoblastic leukemia (ALL). \n",
    "There are different subtypes of ALL, with the two main groups being B-cell lymphoblastic leukemia (affecting immature B-cell lymphocytes) and T-cell lymphoblastic leukemia (affecting immature T-cell lymphocytes). \n",
    "Within each of these broad types, there are further classifications based on commonly observed genetic changes such as large chromosomal rearragements. \n",
    "\n",
    "In this dataset ([SRA Accession PRJNA548203](https://www.ncbi.nlm.nih.gov/bioproject/?term=PRJNA548203)), we have 4 groups of samples: \n",
    "\n",
    "* `ETV6-RUNX1` (4 replicates): samples from a type of B-cell precursor ALL characterised by a translocation between chromosomes 12 and 21 known as the _t(12;21) ETV6/RUNX1_ rearrangement.\n",
    "* `HHD` (2 replicates): also a type of B-cell precursor ALL, where extra chromosomes are gained and known as the \"high hyper diploid\" type.\n",
    "* `PRE-T` (2 replicates): a type of T-cell precursor ALL.\n",
    "* `PBMMC` (3 replicates): control samples from healthy pediatric bone marrow mononuclear cells.\n",
    "\n",
    "We will start by showing how to read and preprocessing the data for one of these samples only. \n",
    "We will then show how to apply the preprocessing to all samples, after which we integrate them together taking into account batch effects inherent to these type of data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941787b7-2077-4485-815d-d4861d94e1eb",
   "metadata": {},
   "source": [
    "### Setting up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b4f8e7-b046-42f9-bf1e-1fa15a29eaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "from scipy.stats import median_abs_deviation\n",
    "from scipy.sparse import csr_matrix\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import anndata as ad\n",
    "import pybiomart as bm\n",
    "import seaborn as sns\n",
    "\n",
    "# set plotting theme\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a21cb2-45d0-40af-9471-d234cde31922",
   "metadata": {},
   "source": [
    "<a id=\"rna_correction\"></a>\n",
    "## 1. Ambient RNA correction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585c9acc-afe5-4bfb-8580-7794498ccbe6",
   "metadata": {},
   "source": [
    "We remove ambient RNA from the dataset, typically using the raw dataset with empty droplets.  In our example here, we use CellBender, which is currently one of the best tools for ambient RNA correction.  \n",
    "\n",
    "![How to read a barcode-rank plot. [Source](https://cellbender.readthedocs.io/en/latest/introduction/index.html)](https://cellbender.readthedocs.io/en/latest/_images/UMI_curve_defs.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8439f07",
   "metadata": {},
   "source": [
    "However, because of VM and time limitations, we will not run this step.  To give you an idea of runtime, the PBMC 10k dataset on a server with 12 cores and 96 GB RAM takes about five hours, [according to this CellRanger post](https://www.10xgenomics.com/analysis-guides/background-removal-guidance-for-single-cell-gene-expression-datasets-using-third-party-tools).  It can be made much faster with CUDA GPU using the `--cuda` argument, if CUDA GPU is available.  Below are the steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a9adde-a7d6-453f-bdec-fd2a2d390752",
   "metadata": {},
   "source": [
    "First, we create an anndata h5ad file from the raw CellRagner output.  In this example, let us use one of the replicates of the ETV6/RUNX1 subtype.  Note: The block of code below is written in a raw cell (not a code cell), to prevent you from accidentally running this step."
   ]
  },
  {
   "cell_type": "raw",
   "id": "cfd76ef8-e33e-47c7-9088-1ee8d1e05336",
   "metadata": {},
   "source": [
    "# These paths are specific to this demo only, where the root path is the root of the course materials repo.\n",
    "# You may specify your specific input and output directories when recreating this step in your local machine or HPC.\n",
    "# All paths must exist prior to run.\n",
    "\n",
    "prefix_inputs = \"../Data/cellranger/CellRanger_Outputs\"\n",
    "prefix_outputs = \"../Data/results/02\"\n",
    "\n",
    "os.makedirs(f\"{prefix_outputs}/cellranger_h5ad\", exist_ok=True)\n",
    "os.makedirs(f\"{prefix_outputs}/cellbender\", exist_ok=True)\n",
    "\n",
    "ETV6_RUNX1_1 = sc.read_10x_mtx(f\"{prefix_inputs}/SRR9264343/outs/raw_feature_bc_matrix/\")\n",
    "ETV6_RUNX1_1.write(f\"{prefix_outputs}/cellranger_h5ad/SRR9264343.raw.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ea3685-6f19-484c-a276-16a23ecd514d",
   "metadata": {},
   "source": [
    "We then go to a bash terminal to run CellBender.  CellBender usage is described [here](https://cellbender.readthedocs.io/en/latest/usage/index.html).  In this example, Cellbender is run using the official, GPU-enabled docker image available from the Google Container Registry (GCR) (see [Github page](https://github.com/broadinstitute/CellBender)):\n",
    "\n",
    "`us.gcr.io/broad-dsde-methods/cellbender:latest`  "
   ]
  },
  {
   "cell_type": "raw",
   "id": "1575650c-df9e-491f-9f6b-b31ac03f762e",
   "metadata": {},
   "source": [
    "#!/usr/bin/env bash\n",
    "\n",
    "PREFIX_INPUTS=\"../Data/CellRanger_Outputs\"\n",
    "PREFIX_OUTPUTS=\"../Data/results/02\"\n",
    "\n",
    "# Pull the image, and create a local copy called `cellbender.sif`\n",
    "singularity pull cellbender.sif docker://us.gcr.io/broad-dsde-methods/cellbender:latest\n",
    "\n",
    "# With the .sif file ready, run below:  \n",
    "singularity exec cellbender.sif \\\n",
    "    cellbender remove-background \\\n",
    "    --cuda \\\n",
    "\t--input \"${PREFIX_OUTPUTS}/cellranger_h5ad/SRR9264343.raw.h5ad\" \\\n",
    "\t--output \"${PREFIX_OUTPUTS}/cellbender/SRR9264343.denoised.h5\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c047d6-b1aa-4038-9682-07c5cf7ff234",
   "metadata": {},
   "source": [
    "Several outputs will be written, but below are main outputs.\n",
    "1. `$PREFIX_OUTPUTS/cellbender/SRR9264343.denoised.h5` - This is the full count matrix as an h5 file, with background RNA removed, but all the original droplet barcodes retained.  \n",
    "2. `$PREFIX_OUTPUTS/cellbender/SRR9264343.denoised_filtered.h5` - This is the filtered count matrix as an h5 file, with background RNA removed. \"Filtered\" means only droplet barcodes of real cells are retained.  That is, it retains only droplets with a > 50% posterior probability of containing cells.  \n",
    "\n",
    "Back in your notebook, you can open the output as an AnnData file, and use it for downstream analyses."
   ]
  },
  {
   "cell_type": "raw",
   "id": "ed332c12",
   "metadata": {},
   "source": [
    "ETV6_RUNX1_1 = sc.read_10x_h5(\"$PREFIX_OUTPUTS/cellbender/SRR9264343.denoised_filtered.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74755de3-295b-410c-9872-0f85d55fe672",
   "metadata": {},
   "source": [
    "<a id=\"reading_data\"></a>\n",
    "## 2. Reading data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9d4b17-d7b1-419b-b37a-d68ff90b12b2",
   "metadata": {},
   "source": [
    "As we do not run CellBender in this demo, we use the filtered outputs of CellRanger, instead.  We start by reading the data using one of the read functions from `scanpy` ([documented here](https://scanpy.readthedocs.io/en/stable/api/reading.html)). In our case, we have our data as [matrices from CellRanger](https://www.10xgenomics.com/support/software/cell-ranger/latest/analysis/outputs/cr-outputs-mex-matrices), so we use the function `sc.read_10x_mtx()`, which takes a directory as its input.  \n",
    "\n",
    "We read one of the replicates of the ETV6/RUNX1 subtype:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd598ffc-5bbf-45b1-aac9-903bb00e8881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These paths are specific to this demo only, where root is the root of the course materials repo.\n",
    "# You may specify your specific input and output directories when recreating this in your local machine or HPC.\n",
    "prefix_inputs = \"../Data/cellranger/CellRanger_Outputs\"\n",
    "prefix_outputs = \"../Data/results/02\"\n",
    "\n",
    "os.makedirs(prefix_outputs, exist_ok=True)\n",
    "\n",
    "ETV6_RUNX1_1 = sc.read_10x_mtx(f\"{prefix_inputs}/SRR9264343/outs/filtered_feature_bc_matrix/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3235aed7-d5cc-4e5d-8076-69dbfe9095a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ETV6_RUNX1_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114e5a0f-de2b-49db-a157-a06b9f4b9117",
   "metadata": {},
   "source": [
    "This object stores several pieces of information, including: \n",
    "\n",
    "- A matrix of raw counts, with samples as rows and genes as columns. This can be retrived with the `.X` accessor.\n",
    "- Metadata about the barcodes (cells), which can be retrieved using the `.obs` accessor. \n",
    "- Metadata about the genes, which can be retrived using the `.var` accessor.\n",
    "\n",
    "In the output above, we get indication of the number of barcodes (`n_obs`) and genes (`n_vars`). \n",
    "\n",
    "![Diagram of the AnnData object type. [Source](https://scanpy.readthedocs.io/en/stable/usage-principles.html)](https://falexwolf.de/img/scanpy/anndata.svg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de17654-4846-4efb-937a-808edb9d5899",
   "metadata": {},
   "source": [
    "<a id=\"gene_annotation\"></a>\n",
    "## 3. Gene Annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d73de2a-3054-4407-9cf5-75fb909d0cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ETV6_RUNX1_1.var"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ba0334-a730-4925-a7cb-b7010e09186b",
   "metadata": {},
   "source": [
    "We can see that our gene ids use ENSEMBL identifiers. \n",
    "For each of these identifiers, we would like to know information about common gene names and also the chromosome, so we can identify mitochondrial genes. \n",
    "\n",
    "We will use the `pybiomart` package, which accesses the Biomart database containing information about genes for many species. \n",
    "You can learn more about the package usage from [its documentation](https://jrderuiter.github.io/pybiomart/usage.html). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2136cb-942b-4852-bb22-a6d490510d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to the Human genes database (GRCh38.p14)\n",
    "h38_mart = bm.Dataset(name=\"hsapiens_gene_ensembl\",\n",
    "                      host=\"http://www.ensembl.org\")\n",
    "\n",
    "# retrieve gene information\n",
    "h38_genes = h38_mart.query(attributes=[\"ensembl_gene_id\", \"external_gene_name\", \"chromosome_name\"])\n",
    "\n",
    "# rename the columns\n",
    "h38_genes = h38_genes.rename(columns={\"Gene stable ID\": \"gene_ids\", \"Gene name\": \"gene_name\", \"Chromosome/scaffold name\": \"chrom\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46d4909-4c90-4fe9-b909-c1aac6ed8987",
   "metadata": {},
   "source": [
    "This returns a Pandas DataFrame object: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387fab86-6892-496a-a67a-f5e65668503c",
   "metadata": {},
   "outputs": [],
   "source": [
    "h38_genes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c22df39-cf8e-4b52-a850-1aa64a78f0d7",
   "metadata": {},
   "source": [
    "We can now merge this DataFrame with the DataFrame from our AnnData metadata:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796ed04d-bee8-41de-a615-dbdb06ad7918",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_annot = (\n",
    "  ETV6_RUNX1_1.var\n",
    "  .merge(h38_genes, how=\"left\", on=\"gene_ids\")\n",
    "  .set_axis(ETV6_RUNX1_1.var.index)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24328a9d-9c37-4d00-af86-2c1edf86860c",
   "metadata": {},
   "source": [
    "Finally, we re-annotate our AnnData, being careful to ensure the order of our genes is the same as in the original AnnData object: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49eb4cb-4a9e-40d6-ab11-e27e135681b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ETV6_RUNX1_1.var = gene_annot.loc[ETV6_RUNX1_1.var_names]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2201ee8e-6aa4-4081-9796-b69da8b48cad",
   "metadata": {},
   "source": [
    "We will keep only genes in the autosomes, X, Y and MT chromosome (i.e. remove genes in unassembled scaffolds):  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52f38aa-3538-42ad-a3f2-e881feb167a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_to_keep = (\n",
    "  ETV6_RUNX1_1.var[\"chrom\"]\n",
    "  .isin([str(i) for i in range(1, 23)] + [\"X\", \"Y\", \"MT\"])\n",
    ")\n",
    "ETV6_RUNX1_1 = ETV6_RUNX1_1[:, vars_to_keep].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4357e025-0677-40ad-9a86-5f67cfa875e6",
   "metadata": {},
   "source": [
    "Note the use of the `.copy()` method. This ensures that we make a new copy of the object (which we replace back into `ETV6_RUNX1_1`), rather than a \"View\" of the original object.  \n",
    "\n",
    "Finally, we create a variable in our gene metadata to indicate whether a gene is mitochondrial or not. \n",
    "We will use this later on when we do quality control.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3677aa3-04e0-4365-8523-c9d305082314",
   "metadata": {},
   "outputs": [],
   "source": [
    "ETV6_RUNX1_1.var[\"mt\"] = ETV6_RUNX1_1.var[\"chrom\"] == \"MT\"\n",
    "ETV6_RUNX1_1.var[\"mt\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a085e5-8f97-477d-bcf4-fb52afa9b2ef",
   "metadata": {},
   "source": [
    "<a id=\"filtering\"></a>\n",
    "## 4. Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8efdde9-8874-41fd-9120-73821d31fece",
   "metadata": {},
   "source": [
    "We start by doing some exploratory analysis of our raw count data, namely in terms of:  \n",
    "\n",
    "- number of total counts per barcode  \n",
    "- number of detected genes per barcode  \n",
    "- fraction of counts in mitochondrial genes  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb16c11-3d37-4a7f-8426-e39ef8d4f711",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.calculate_qc_metrics(\n",
    "    ETV6_RUNX1_1, \n",
    "    qc_vars=[\"mt\"], \n",
    "    inplace=True, \n",
    "    percent_top=[20], \n",
    "    log1p=True\n",
    ")\n",
    "ETV6_RUNX1_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9eeb64-90bf-4d56-a244-68404c3ef7bf",
   "metadata": {},
   "source": [
    "This function added several metrics for each barcode, i.e. our observations: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd286e53-a5a1-41de-9133-a81c1d080129",
   "metadata": {},
   "outputs": [],
   "source": [
    "ETV6_RUNX1_1.obs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de28ecb-ab83-474c-a870-0827b1bd6e09",
   "metadata": {},
   "source": [
    "And also to our genes, i.e. variables: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fc1607-0ee7-4508-9bd8-9d4995f89dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "ETV6_RUNX1_1.var"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0b3b34-f5c4-464e-82ed-98073b38501b",
   "metadata": {},
   "source": [
    "### 4.1 Filtering barcodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a917cb10-a51f-48a2-9989-55ab39e6e8ae",
   "metadata": {},
   "source": [
    "Since `ETV6_RUNX1_1.obs` is a regular DataFrame, we can use standard plotting libraries to visualise these statistics.  \n",
    "For example, using the popular Seaborn library: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f9beb4-4ef9-4f81-ba34-f7739f8172a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(ETV6_RUNX1_1.obs, x=\"total_counts\", bins=100)\n",
    "sns.displot(ETV6_RUNX1_1.obs, x=\"pct_counts_mt\", bins=100)\n",
    "sns.scatterplot(ETV6_RUNX1_1.obs, x=\"total_counts\", y=\"n_genes_by_counts\", hue=\"pct_counts_mt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c068c5ac-3d42-45a3-9e05-59772efb7670",
   "metadata": {},
   "source": [
    "Alternatively, we can use `scanpy`'s own plotting functions (histogram is not available, but we can do violin plots instead):  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73cf5b3e-abaf-49fe-b559-003e840fc72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.violin(ETV6_RUNX1_1, \"total_counts\")\n",
    "sc.pl.violin(ETV6_RUNX1_1, \"pct_counts_mt\")\n",
    "sc.pl.scatter(ETV6_RUNX1_1, \"total_counts\", \"n_genes_by_counts\", color=\"pct_counts_mt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c250d5-83af-40dd-8371-c175ab12375a",
   "metadata": {},
   "source": [
    "We can even do several violin plots at once: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8a0878-72e1-46a4-a885-c27eb601b87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.violin(\n",
    "  ETV6_RUNX1_1,\n",
    "  [\"n_genes_by_counts\", \"total_counts\", \"pct_counts_mt\"],\n",
    "  multi_panel=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253fe0ed-9dc3-4bcf-b6ba-346d919e0c45",
   "metadata": {},
   "source": [
    "We can filter our object based on hard thresholds set manually. \n",
    "Alternatively, we can define a function that removes outliers based on the observed distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78ccf1d-1cd7-4e17-b548-52ae379842b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_outlier(adata, metric: str, nmads: int):\n",
    "  M = adata.obs[metric]\n",
    "  \n",
    "  outlier = (M < np.median(M) - nmads * median_abs_deviation(M)) | (\n",
    "      np.median(M) + nmads * median_abs_deviation(M) < M\n",
    "  )\n",
    "  return outlier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba14358-f731-4213-a271-5c7e27c5c88b",
   "metadata": {},
   "source": [
    "The function returns `True` or `False` depending on whether the value exceeds the specified value of median absolute deviation. \n",
    "For example: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5dbd188-6b2f-454d-aaa5-bfe3383085d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create barcode metadata column indicating counts outliers\n",
    "ETV6_RUNX1_1.obs[\"counts_outlier\"] = is_outlier(ETV6_RUNX1_1, \"log1p_total_counts\", 5)\n",
    "\n",
    "# visualise\n",
    "sns.displot(ETV6_RUNX1_1.obs, x=\"log1p_total_counts\", hue=\"counts_outlier\", multiple=\"stack\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80dae879-d892-447a-8c6c-ada48f5c000b",
   "metadata": {},
   "source": [
    "Note that we used the log-transformed counts, as its distribution is less skewed and therefore more suitable for the MAD-based filtering we are doing.  \n",
    "\n",
    "We can repeat this for number of detected genes (also log-transformed) and the percentage of counts in the top 20 genes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01510990-a2dd-41fb-801b-aba8e1b35417",
   "metadata": {},
   "outputs": [],
   "source": [
    "ETV6_RUNX1_1.obs[\"genes_outlier\"] = is_outlier(ETV6_RUNX1_1, \"log1p_n_genes_by_counts\", 5)\n",
    "sns.displot(ETV6_RUNX1_1.obs, x=\"log1p_n_genes_by_counts\", hue=\"genes_outlier\", multiple=\"stack\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e801378f-3fc0-40b3-a991-ddb65ea2eba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ETV6_RUNX1_1.obs[\"topgenes_outlier\"] = is_outlier(ETV6_RUNX1_1, \"pct_counts_in_top_20_genes\", 5)\n",
    "sns.displot(ETV6_RUNX1_1.obs, x=\"pct_counts_in_top_20_genes\", hue=\"topgenes_outlier\", multiple=\"stack\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4108d607-fa5d-4896-aa82-d3336425e7a9",
   "metadata": {},
   "source": [
    "We also check for outliers with regards to percentage of mitochondrial counts, where we use more strict filters: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ba9c97-e0ad-407d-8d89-6547b6545a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ETV6_RUNX1_1.obs[\"mito_outlier\"] = is_outlier(ETV6_RUNX1_1, \"pct_counts_mt\", 3) | (ETV6_RUNX1_1.obs[\"pct_counts_mt\"] > 8)\n",
    "sns.displot(ETV6_RUNX1_1.obs, x=\"pct_counts_mt\", hue=\"mito_outlier\", multiple=\"stack\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38eb9047-fd82-4221-afb3-832d852a4f0d",
   "metadata": {},
   "source": [
    "Finally, we create a variable which is the union of these conditions, i.e. if the barcode is determined an outlier of _any_ of our filters, then we consider it to be an outlier: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68adc53f-c32b-444f-b248-5e78a4b318ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "ETV6_RUNX1_1.obs[\"outlier\"] = ETV6_RUNX1_1.obs[\"genes_outlier\"] | ETV6_RUNX1_1.obs[\"genes_outlier\"] | ETV6_RUNX1_1.obs[\"topgenes_outlier\"] | ETV6_RUNX1_1.obs[\"mito_outlier\"]\n",
    "\n",
    "ETV6_RUNX1_1.obs[\"outlier\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9099a1d-2d66-4f4d-98e9-48259218efef",
   "metadata": {},
   "source": [
    "We can visualise our scatterplot of counts vs detected genes to see which barcodes will be removed: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27a63ce-e667-4b76-9259-54a1f7701875",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(ETV6_RUNX1_1.obs, \n",
    "                x = \"total_counts\", \n",
    "                y = \"n_genes_by_counts\",\n",
    "                hue = \"outlier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33f82bb-9f45-4f6f-98de-0ae424ac92d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ETV6_RUNX1_1 = ETV6_RUNX1_1[~ETV6_RUNX1_1.obs[\"outlier\"], :].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21d9049-ba70-4015-8c2a-da7c3e6bbf25",
   "metadata": {},
   "source": [
    "The barcodes we are left with after this filtering we will now consider to be cells. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94428987-0634-4293-8dce-00d7c374c1bd",
   "metadata": {},
   "source": [
    "### 4.2 Filtering Genes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804c98dc-7ff0-4aa0-ad39-a29d08c703cc",
   "metadata": {},
   "source": [
    "In the same way that we explored several metrics for barcodes, we can also explore them for genes. However, as we will see, downstream analysis can focus on variable genes and will mostly ignore genes for which there is very little data. Therefore, we don't perform as strict filtering on genes as we do on barcodes.    \n",
    "\n",
    "Still, it is useful to remove undetected genes, i.e. those with zero total counts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeba34f4-6671-49b1-8970-98478e37ffb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count of genes with zero counts\n",
    "ETV6_RUNX1_1.var[\"total_counts\"].eq(0).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e444e0a-4d56-4b3c-8e1e-c497d63305b6",
   "metadata": {},
   "source": [
    "We can use the `sc.pp.filter_genes()` function to do this:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed1cd8e-7399-4a25-a257-8d97ca40e90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.filter_genes(ETV6_RUNX1_1, min_counts=0)\n",
    "\n",
    "# check number  of genes left\n",
    "ETV6_RUNX1_1.n_vars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2cb275-9b40-4958-adca-ed052050b11f",
   "metadata": {},
   "source": [
    "### 4.3 Doublet removal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15de67c9",
   "metadata": {},
   "source": [
    "In this special barcode filtering step, we remove droplet barcodes that may contain more than one cell or nucleus. This is an important step because, unremoved, these droplets known as \"doublets\" can be misclassified and thus confound downstream analysis.  \n",
    "\n",
    "Below is what our cell barcode metadata container, `.obs`, looks like at the moment.  It has outputs saed from the previous filtering steps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0dcda86-6836-4f9c-bba1-bb309c81bd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "ETV6_RUNX1_1.obs.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b458b28",
   "metadata": {},
   "source": [
    "Here we run a doublet-detection algorithm that is available in scanpy, called Scrublet ([Wolock et al., 2019](https://doi.org/10.1016/j.cels.2018.11.005))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1d3fb3-cdb9-4bdd-9324-b1e562817f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.scrublet(ETV6_RUNX1_1)\n",
    "ETV6_RUNX1_1.obs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983c35b9-b513-4de0-85cb-6634348d25c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ETV6_RUNX1_1.obs.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba46d87e",
   "metadata": {},
   "source": [
    "Notice that running Scrublet has added `predicted_doublet` and `doublet_score` to `ETV6_RUNX1_1.obs`. We can check how many have been predicted as doublets by Scrublet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46218285-30fd-4739-bfb5-dab9c927c957",
   "metadata": {},
   "outputs": [],
   "source": [
    "ETV6_RUNX1_1.obs[\"predicted_doublet\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837cafff",
   "metadata": {},
   "source": [
    "At the moment, our count matrix remains the same as the previous step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8692a6a7-a06f-4aca-b215-eca9c9a1d5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "ETV6_RUNX1_1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c582f1d4",
   "metadata": {},
   "source": [
    "One can use the above results by filtering out the cells called as doublets before moving on to the next step.  Another option is to wait until after clustering, and filter out clusters with high doublet scores ([reference](https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering.html)).  There is also no reason to be limited by one doublet detection method--one can use multiple methods, and filter out the barcodes called as doublets by the different methods.\n",
    "\n",
    "For this demo, we simply filter out the doublets before moving forward.  Below, the code retains all the barcodes where `predicted_doublet` is False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73bf616-5bd1-486c-af35-e44eaef0a522",
   "metadata": {},
   "outputs": [],
   "source": [
    "ETV6_RUNX1_1 = ETV6_RUNX1_1[~ETV6_RUNX1_1.obs[\"predicted_doublet\"], :].copy()\n",
    "ETV6_RUNX1_1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f458f4b",
   "metadata": {},
   "source": [
    "Other doublet detection tools you can check out are [Solo](https://docs.scvi-tools.org/en/stable/user_guide/models/solo.html), [DoubletDetection](https://github.com/JonathanShor/DoubletDetection), and [DoubletFinder](https://github.com/chris-mcginnis-ucsf/DoubletFinder?tab=readme-ov-file).  The latter is one of the best doublet detection methods according to a benchmarking paper ([Xi and Li, 2021](https://doi.org/10.1016/j.cels.2020.11.008)) It is implemented in Seurat, but can be implemented in the same notebook as your Python analysis--check out doublet detection section of the [Single-cell Best Practices online book](https://www.sc-best-practices.org/preprocessing_visualization/quality_control.html#doublet-detection)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992f0ea0-b99d-4319-bb05-ee9db49e0f66",
   "metadata": {},
   "source": [
    "<a id=\"normalisation\"></a>\n",
    "## 4. Normalisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04bf1dee-79cb-46a4-a674-c1e80a4efff3",
   "metadata": {},
   "source": [
    "There are several normalisation methods available for single-cell RNA-seq data. Two of those methods are:  \n",
    "\n",
    "- **Pearson residuals:** this method models the count data using a negative binomial regression model to regress out the effects of total count differences between cells and uses the residuals from the model as the normalised count values.  \n",
    "- **Shifted logarithm:** scales the counts by a cell-specific size factor (based on the total counts in that cell) followed by taking its logarithm. Despite being a relatively simple method, it has been shown to perform well in downstream analysis such as dimensionality reduction and clustering.  \n",
    "\n",
    "We will use the `layers` component of the AnnData object, which can be used to store different versions of our count matrix.  This is a good way to keep several versions of our data in place, especially as we explore different methods of normalisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19ff127-44cd-43d6-98a3-d0139208d515",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep a copy of the raw counts in the object as a backup\n",
    "ETV6_RUNX1_1.layers[\"counts\"] = ETV6_RUNX1_1.X.copy()\n",
    "\n",
    "# create a new layer for Pearson residuals\n",
    "ETV6_RUNX1_1.layers[\"pearson\"] = ETV6_RUNX1_1.X.copy()\n",
    "sc.experimental.pp.normalize_pearson_residuals(ETV6_RUNX1_1, layer=\"pearson\")\n",
    "# convert to sparse matrix (efficient and saves memory)\n",
    "ETV6_RUNX1_1.layers[\"pearson\"] = csr_matrix(ETV6_RUNX1_1.layers[\"pearson\"])\n",
    "\n",
    "# create new layer for log-normalised counts\n",
    "ETV6_RUNX1_1.layers[\"logcounts\"] = ETV6_RUNX1_1.X.copy()\n",
    "sc.pp.normalize_total(ETV6_RUNX1_1, layer=\"logcounts\", target_sum=None)\n",
    "sc.pp.log1p(ETV6_RUNX1_1, layer=\"logcounts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057dd3e6-e051-4ce6-8b6c-79ce438251fb",
   "metadata": {},
   "source": [
    "We can visualise the distributions and correlations of the normalised data as a pair plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f9f150-b7a7-4209-98be-04c6393e4ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: np.nansum() only works in regular matrix, so we coerce from the sparse matrix format\n",
    "sns.pairplot(\n",
    "  pd.DataFrame({\"Raw counts\": np.nansum(ETV6_RUNX1_1.layers[\"counts\"].toarray(), 1),\n",
    "              \"Log-normalised counts\": np.nansum(ETV6_RUNX1_1.layers[\"logcounts\"].toarray(), 1),\n",
    "              \"Pearson residuals\": np.nansum(ETV6_RUNX1_1.layers[\"pearson\"].toarray(), 1)})\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667bba61-dcaf-4986-a801-64ac84b596ec",
   "metadata": {},
   "source": [
    "As we can see, while the log-normalised data is fairly well correlated with the original counts, the Pearson residuals are not. This is because the Pearson residuals represent the output of a model taking into account the total counts of the cell, thus the values represent whether the expression is above or below the expected value of expression for that gene.  \n",
    "\n",
    "There is no \"right method\" when it comes to normalisation, and often several methods should be explored, alongside a knowledge of the biology. The Pearson residuals normalisation is argued to capture more of the relevant biological signal ([Lause et al. 2021](https://doi.org/10.1186/s13059-021-02451-7)) and the [Scanpy documentation](https://scanpy.readthedocs.io/en/stable/tutorials/experimental/pearson_residuals.html) gives details about using this normalisation for downstream analysis.  \n",
    "\n",
    "However, as this method is computationally more demanding, we will proceed with the log normalisation. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e31142c-d331-4340-8575-5a95157c8205",
   "metadata": {},
   "source": [
    "<a id=\"workflow\"></a>\n",
    "## 5. Preprocessing workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6fe0bf-4564-43a9-8915-bb10122263f2",
   "metadata": {},
   "source": [
    "Now that we have explored these things with a single sample, we can bring it all together to process all our samples. We will define a function that performs the preprocessing steps covered:  \n",
    "\n",
    "* Read the CellRanger matrix\n",
    "* Add gene annotation\n",
    "* Filter barcodes based on different metrics\n",
    "* Normalise the counts (using the simpler log-normalisation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc0c43f-e17c-44aa-8b7b-f81c6fd87f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sc_preprocess(path: str, gene_annot: pd.DataFrame):\n",
    "    \n",
    "    print(\"1. Reading data matrix\")\n",
    "    adata = sc.read_10x_mtx(path)\n",
    "    \n",
    "    print(\"2. Adding gene metadata\")\n",
    "    gene_annot = adata.var.merge(gene_annot, how=\"left\", on=\"gene_ids\")\n",
    "    gene_annot.set_index(adata.var.index, inplace=True)\n",
    "    \n",
    "    if (adata.var[\"gene_ids\"] == gene_annot[\"gene_ids\"]).all():\n",
    "        adata.var = gene_annot\n",
    "    else: \n",
    "        print(\"The gene order was not the same!\")\n",
    "        return\n",
    "    \n",
    "    vars_to_keep = adata.var[\"chrom\"].isin([str(i) for i in range(1, 23)] + [\"X\", \"Y\", \"MT\"])\n",
    "    adata = adata[:, vars_to_keep].copy()\n",
    "\n",
    "    adata.var[\"mt\"] = adata.var[\"chrom\"] == \"MT\"\n",
    "\n",
    "    print(\"3. Calculating QC metrics and filtering\")\n",
    "    # Generate qc metrics\n",
    "    sc.pp.calculate_qc_metrics(\n",
    "        adata, \n",
    "        qc_vars=[\"mt\"], \n",
    "        inplace=True, percent_top=[20], \n",
    "        log1p=True\n",
    "        )\n",
    "    \n",
    "    # Identify outliers per qc metric\n",
    "    adata.obs[\"counts_outlier\"] = is_outlier(adata, \"log1p_total_counts\", 5)\n",
    "    adata.obs[\"genes_outlier\"] = is_outlier(adata, \"log1p_n_genes_by_counts\", 5)\n",
    "    adata.obs[\"topgenes_outlier\"] = is_outlier(adata, \"pct_counts_in_top_20_genes\", 5)\n",
    "    adata.obs[\"mito_outlier\"] = is_outlier(adata, \"pct_counts_mt\", 3) | (adata.obs[\"pct_counts_mt\"] > 8)\n",
    "\n",
    "    # Identify outliers based on ALL qc metrics \n",
    "    adata.obs[\"outlier\"] = (\n",
    "        adata.obs[\"counts_outlier\"]  \n",
    "        | adata.obs[\"genes_outlier\"] \n",
    "        | adata.obs[\"topgenes_outlier\"] \n",
    "        | adata.obs[\"mito_outlier\"]\n",
    "    )\n",
    "    # Remove outliers\n",
    "    adata = adata[~adata.obs[\"outlier\"]].copy()\n",
    "\n",
    "    # Perform gene filtering\n",
    "    sc.pp.filter_genes(adata, min_cells=1)\n",
    "\n",
    "    # Remove doublets\n",
    "    sc.pp.scrublet(adata)\n",
    "    adata = adata[~adata.obs[\"predicted_doublet\"], :].copy()\n",
    "\n",
    "    print(\"4. Applying normalisations\")\n",
    "    adata.layers[\"counts\"] = adata.X.copy()\n",
    "\n",
    "    sc.pp.normalize_total(adata, target_sum=None)\n",
    "    sc.pp.log1p(adata)\n",
    "\n",
    "    return adata\n",
    "\n",
    "# our outlier detection function from before\n",
    "def is_outlier(adata, metric: str, nmads: int):\n",
    "    M = adata.obs[metric]\n",
    "    outlier = (M < np.median(M) - nmads * median_abs_deviation(M)) | (\n",
    "            np.median(M) + nmads * median_abs_deviation(M) < M\n",
    "    )\n",
    "    return outlier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e78bbc-8638-4b3b-8c6b-0752595ccdc0",
   "metadata": {},
   "source": [
    "We apply this function to each of our samples, looping through each of them based on our sample information DataFrame: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ca92b9-b027-46fd-90fe-d2ee7edaaa6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_info = pd.read_table(\"../Data/sample_sheet.tsv\")\n",
    "sample_info = sample_info.rename(columns={\"Sample\": \"sample_id\", \n",
    "                                          \"SampleName\": \"sample_name\", \n",
    "                                          \"SampleGroup\": \"sample_group\"})\n",
    "sample_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f096033-6dc8-40a8-97e7-fe82bd60c254",
   "metadata": {},
   "source": [
    "To make it doable computationally, we restrict things to a few samples only: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0518dbbe-c632-45dc-b95e-f02a0aa5bba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary to hold all AnnData objects\n",
    "adata = dict.fromkeys(sample_info[\"sample_id\"])\n",
    "\n",
    "# read all samples\n",
    "for sample in adata.keys():\n",
    "  print(f\"\\nReading {sample}\")\n",
    "  adata[sample] = sc_preprocess(\n",
    "    f\"../Data/CellRanger_Outputs/{sample}/outs/filtered_feature_bc_matrix/\",\n",
    "    h38_genes\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b6ea64-f1a8-4e51-b2db-4c8f33a1b108",
   "metadata": {},
   "source": [
    "Our next step is to combine all these separate objects into a single AnnData object, with information about the sample that each barcode comes from.  \n",
    "\n",
    "Before doing that, we will grab the gene metadata, which unfortunately gets lost when combining multiple AnnData objects (see [this post](https://discourse.scverse.org/t/loosing-anndata-var-layer-when-using-sc-concat/1605) for details)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f9189a-48ce-4c95-bf6b-9610f772b1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab all var DataFrames from our dictionary\n",
    "all_var = [x.var for x in adata.values()]\n",
    "# concatenate them\n",
    "all_var = pd.concat(all_var, join=\"outer\")\n",
    "# we keep only some columns of interest\n",
    "all_var = all_var[[\"gene_ids\", \"gene_name\", \"chrom\"]]\n",
    "# remove duplicates\n",
    "all_var = all_var[~all_var.duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6610fd0-4bd0-4ef4-b07a-f7188a669886",
   "metadata": {},
   "source": [
    "Now we have all the gene metadata, we proceed with combining all these objects together using scanpy's concatenation function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c612ac7-cbf9-4aeb-8e66-c7b34be630bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.concat(adata, join=\"outer\", label=\"sample_id\", index_unique=\"-\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b78eb8-1081-41e2-93d7-32fe36f279bd",
   "metadata": {},
   "source": [
    "After concatenation, we can add back the gene metadata that we collected earlier: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ea27b6-2a5d-4781-bfc1-322b3eb2783d",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.var = all_var.loc[adata.var_names]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b976488f-fd08-4e3c-b380-f379b93adcc3",
   "metadata": {},
   "source": [
    "And we add the information about our samples to the cells' metadata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c418fa0e-a08e-44c0-81c9-32ee3e642d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs = (\n",
    "  adata.obs\n",
    "  .merge(sample_info, how=\"left\", on=\"sample_id\")\n",
    "  .set_axis(adata.obs.index)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb4acba-182b-4ce8-9360-055fc9d58370",
   "metadata": {},
   "source": [
    "Note we used `.set_axis(adata.obs.index)` to ensure we retained the rowname indexes of the table as the original (i.e. the barcode names). If we don't do this, it will generate an invalid anndata object.  \n",
    "\n",
    "Finally, with the full data merged, we save this object for downstream analysis: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9afa268-237b-4ba2-a6e0-abfe9877ef54",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.write(f\"{prefix_outputs}/caron_filtered_full.h5ad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef0b031-163f-4077-b20d-61c990988032",
   "metadata": {},
   "source": [
    "We are now ready to perform downstream analyses."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
